
# D√©tection de fraude bancaire en Temps R√©el

Ce projet a √©t√© r√©alis√© dans le cadre de la formation Data Analyst √† la Wild Code School. Il simule un flux de transactions bancaires, les analyse via un mod√®le de Machine Learning (XGBoost) et monitore les performances en temps r√©el.

## üë• L'√âquipe (FJK)
* **F** : Fr√©d√©ric Bayen - *Architecture MLOps, Bigquery & Automatisation*
* **K** : Kenji Victor - *Streamlit, Grafana & Prometheus*
* **J** : Jean-Baptiste Leduc - *Data Visualization, Dashboards, Redis & Mod√©lisation XGBoost*

## Architecture du Pipeline

L'application repose sur une architecture micro-services conteneuris√©e avec Docker.

```text
[ SOURCE : Donn√©es CSV ]
      |
      | Lecture (streamenvoi.py)
      v
[ CERVEAU : Docker - API ] <---------------------------+
+-----------------------+       +-------------------+  |
|  streamrecepteur.py   | ----> |  ML_XGBoost.ipynb |  | 
|     (FastAPI)         | <---- |  Mod√®le XGBoost   |  |    
+-----------------------+       +-------------------+  |
      |                                                |
      | R√©sultats (LPUSH)                          |
      v                                                |
[ STOCKAGE : Docker - Redis ]                          |
+------------------------------------------+           |
|              REDIS (Cache)               |           |
|  - flux_global (Archive BigQuery)        |           |
|  - flux_streamlit (Affichage direct)     |           |
+------------------------------------------+           |
      |                     |                          |
      |                     | Archivage                |
      |                     v                          |
      |                +-------------------+    [ MLOPS : Prefect ]
      |                |   worker_bq.py    |    +-----------------+
      |                | (Envoi BigQuery)  |--->|  retrain.py     |
      |                +-------------------+    |  (Auto-Train)   |
      v                                         +-----------------+
      +-------------------------------------------------+
      | (4) Monitoring                                  |     
      v                                                 v
[ SUPERVISION : Prometheus & Grafana ]             [ TABLEU DE BORD : Streamlit]
+------------------------------------------+    +------------------------------------------+
| - Metrics syst√®me (CPU/RAM conteneurs)   |    | dashboard.py                             |
| - Metrics business (Taux de fraude)      |    | - Dashboarding & Alerting Temps R√©el     |
| - Dashboarding & Alerting Temps R√©el     |    | - EDA                                    |
+------------------------------------------+    +------------------------------------------+
```

---

## Gestion des Donn√©es (Data Engineering)

Le projet utilise le dataset PaySim [(disponible ici sur Kaggle)](https://www.kaggle.com/datasets/mtalaltariq/paysim-data).

Pour simuler un environnement de production r√©el, nous avons cr√©√© un script ```decoupe.py``` pour segmenter les donn√©es :

 - **90% (Historique)** : Utilis√©s pour l'entra√Ænement initial et stock√©s comme base de r√©f√©rence.

 - **10% (Flux Stream)** : Isol√©s pour simuler l'envoi de transactions ligne par ligne par streamenvoi.py.

Cette m√©thode garantit que le mod√®le est test√© sur des donn√©es qu'il n'a jamais rencontr√©es lors de sa phase d'apprentissage initiale.

---

## Lancement Rapide

**Pr√©requis**

   - Docker & Docker Compose install√©s.

   - Cl√© Google Cloud ```gcp-key.json``` √† la racine pour l'acc√®s √† BigQuery.

   - Dataset ```PaySim_stream.csv``` et ```PaySim_historical.csv``` dans le dossier ./data/ r√©cup√©r√©s gr√¢ce √† ```decoupe.py```

**Installation**

1. **Cloner le projet.**

2. **Lancer l'infrastructure :**

```docker compose up --build```

**Acc√®s aux Services**

**Dashboard Streamlit** : http://localhost:8501

**Documentation API** : http://localhost:8000/docs

**Monitoring Grafana** : http://localhost:3000

**Prometheus** : http://localhost:9090

**Processus de r√©entrainement** : ```docker logs -f retrain-automation```

---

## Automatisation MLOps

Le conteneur retrain-automation surveille la table BigQuery via Prefect.

 - Modularit√© : Le seuil de d√©clenchement (```min_rows_to_retrain```), le nombre de transactions r√©cup√©res sur BigQuery  (```limit_sql```) et l'intervalle de v√©rification (```check_interval_secondes```) sont modifiables sans red√©marrage dans ```state.json```.

 - Action : D√®s que le seuil est atteint, le mod√®le est r√©entra√Æn√© sur les nouvelles donn√©es, archiv√©, et l'API est notifi√©e pour charger la nouvelle version instantan√©ment.

---

## Maintenance et R√©initialisation

Pour remettre le projet √† z√©ro :

1. Vider Redis : ```docker exec -it redis-service redis-cli FLUSHALL```

2. Vider BigQuery : ```TRUNCATE TABLE paysim_raw.predictions_transaction```

3. Reset l'automation : Mettre ```last_count``` √† 0 dans le fichier ```state.json```.


## Structure du dossier

```
‚îú‚îÄ‚îÄ data/                  # Datasets (CSV historiques et flux stream)
‚îú‚îÄ‚îÄ grafana/               # Configuration du monitoring
‚îÇ   ‚îú‚îÄ‚îÄ dashboards/        # Fichiers JSON des dashboards (RAM, Principal, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ provisioning/      # Configuration automatique des sources de donn√©es
‚îú‚îÄ‚îÄ notebooks/             # Travail exploratoire et recherche
‚îÇ   ‚îú‚îÄ‚îÄ decoupe.py         # Script de split du dataset (90/10)
‚îÇ   ‚îú‚îÄ‚îÄ EDA_PaySim.ipynb   # Analyse exploratoire des donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ ML_XGBoost.ipynb   # Entra√Ænement et tests du mod√®le
‚îú‚îÄ‚îÄ src/                   # Code source applicatif
‚îÇ   ‚îú‚îÄ‚îÄ API/               # streamrecepteur (FastAPI), streamenvoi et worker_bq
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/         # Interface utilisateur Streamlit (dashboard.py)
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/         # Scripts de traitement des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Fichiers .joblib (pipeline_latest, archives)
‚îÇ   ‚îî‚îÄ‚îÄ retrain/           # Automatisation MLOps (retrain.py)
‚îú‚îÄ‚îÄ docker-compose.yml     # Orchestration des services Docker
‚îú‚îÄ‚îÄ Dockerfile             # Configuration de l'image Python/UV
‚îú‚îÄ‚îÄ prometheus.yml         # Configuration de la collecte des m√©triques
‚îú‚îÄ‚îÄ state.json             # √âtat dynamique et configuration du r√©entra√Ænement
‚îî‚îÄ‚îÄ README.md              # Documentation du projet
```










# Pr√©requis

- **Docker** et **Docker Compose** install√©s sur votre machine.
- Le fichier de donn√©es `PaySim_stream.csv` et `PaySim_historical.csv` plac√© dans le dossier `./data/`.

# Lancement Fast api

1. **Cloner le projet**
2. **Lancer l'environnement avec Docker Compose :**

    ```
   docker compose up --build
    ```
   # arr√™ter le processus
    ```
   docker-compose down
    ```
   # effacer le cache
    ```
   docker system prune -f
    ```

# Comment r√©initialiser tout √† 0 :

1. Lancer le container Redis

2. Excuter la commande : ``` docker exec -it redis-service redis-cli FLUSHALL ```

3. Fermer le container 

4. Lancer bigquery pour r√©ionitialiser la table

5. Excuter la commande :  : ``` TRUNCATE TABLE paysim_raw.predictions_transaction ```

6. Mettre √† jour le fichier src/retrain/lastcount : changer la valeur √† 0




# Ouvrir streamlit

http://localhost:8501/ Dans la barre d'url'

# Afficher les rapports/docu API

http://localhost:8000/report

http://localhost:8000/docs


# poru lancer sans docker

uv run python src/API/streamrecepteur.py

uv run uvicorn src.API.streamrecepteur:app --reload --port 8000

# Pour v√©rifier le process de r√©entrainement du mod√®le : 

```
docker logs -f retrain-automation
```

# Structure du projet

```
fjbk-fraud-detection/
‚îú‚îÄ‚îÄ data/                  # Stockage des datasets bruts et transform√©s (ignorer via .gitignore)
‚îú‚îÄ‚îÄ docs/                  # Documentation technique et choix du dataset
‚îú‚îÄ‚îÄ /grafana               # Configuration du monitoring avec Grafana
‚îÇ   ‚îú‚îÄ‚îÄ /dashboards        # Exports des dashboards depuis Grafana
‚îÇ   ‚îî‚îÄ‚îÄ /provisioning      # Configuration du provisioning
‚îÇ       ‚îú‚îÄ‚îÄ /dashboards    # Fichiers de d√©claration
‚îÇ       ‚îî‚îÄ‚îÄ /datasources   # Fichiers de sources de donn√©es
‚îú‚îÄ‚îÄ model/                 # Stockage mod√®le, preprocessor
‚îú‚îÄ‚îÄ notebooks/             # EDA et Visualisation 
‚îú‚îÄ‚îÄ src/                   # Code source modulaire
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/         # Scripts pour lire les donn√©es 
‚îÇ   ‚îú‚îÄ‚îÄ API                # API
‚îÇ   ‚îú‚îÄ‚îÄ processing/        # Nettoyage et Feature Engineering 
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Entra√Ænement et √©valuation (ML)
‚îÇ   ‚îî‚îÄ‚îÄ dashboard/         # Interface Streamlit 
‚îú‚îÄ‚îÄ tests/                 # Tests unitaires pour le pipeline 
‚îú‚îÄ‚îÄ requirements.txt       # Biblioth√®ques
‚îî‚îÄ‚îÄ README.md              # Guide du projet et m√©thodologie



# redis 

1. faire un uv lock afin de modifier le Dockerfile

2. pour se connecter au conteneur redis:
   => docker exec -it redis-service redis-cli
    
   pour lister les listes dans le redis 
   => KEYS *

   pour vider toutes les listes redis (les conteneurs doivent √™tre allum√©s)
   => docker exec -it redis-service redis-cli FLUSHALL

3. lancer manuellement streamenvoi
   => python src/API/streamenvoi.py

4. pour afficher l'int√©gralit√© de la liste
   => LRANGE liste_fraudes 0 -1 

5. LOGS dans BASH: afin d'obtenir "ALERTE" d√®s que redis re√ßoit une fraude
   => docker-compose logs -f api-recepteur | grep "ALERTE"
   r√©cup√©rer les LOGS worker-bigquery
   => docker logs -f worker-bigquery

6. pour arr√™ter les contenurs Docker:
   => docker-compose stop

   pour supprimer les volumes persistans (suppression aussi de la configuration redis)
   => docker-compose down -v

7. Supprimer dans bigquery : TRUNCATE TABLE `paysim_raw.predictions_transaction`
